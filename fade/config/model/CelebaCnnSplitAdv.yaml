# @package _group_
name: 'CelebaCnnSplit'
backbone: resnet18  # Do not use large net if use local model training. Options: mobile | resnet18 (large)
n_task: 1  # > 0 for task/group adv training. <=0 otherwise
rev_lambda_scale: 1.  # 0 to disable backward from task discriminator. >0 to reverse grad. <0 to normal grad. NOTE this is just a constant scale to the lambda. The real lambda will be further scheduled on run.
n_class: 2  # This depends on dataset.
mid_dim: 256
freeze_backbone: False
freeze_decoder: False
disable_bn_stat: True  # TODO This has to be true if user.no_local_model=True
CDAN_task: False
bottleneck_type: dropout
