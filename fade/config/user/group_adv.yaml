# @package _group_
name: group_adv
loss: xent
group_loss: bce  # bce | sq_bce | xent | wd (Wasserstein distance) | dib | cdan
adv_lambda: 1.  # coef for adv loss.
optimizer:
  name: sgd_sch
  learning_rate: 0.01  # Local learning rate
  personal_learning_rate: 0.09  # Persionalized learning rate to caculate theta aproximately using K steps
privacy:
  enable: false
#    user_clip_norm: -1  # User-DP clip norm (layer wise)
#    user_dp_sigma: -1  # User-DP noise sigma
batch_size: 32
local_epochs: 20
lamda: 0  # Regularization term
K: 5  # Computation steps on local fine-tune